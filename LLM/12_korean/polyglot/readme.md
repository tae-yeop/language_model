https://huggingface.co/EleutherAI/polyglot-ko-1.3b

Polyglot-Ko-1.3B was trained on 863 GB of Korean language data (1.2TB before processing)


Furthermore, in order to avoid the model memorizing and generating personally identifiable information (PII) in the training data, we masked out the following sensitive information in the pre-processing stage: