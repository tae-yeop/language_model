{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c218793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    SchedulerType,\n",
    "    get_scheduler,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686beac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 4358/4358 [00:00<00:00, 18857.11 examples/s]\n",
      "Generating train split: 100%|██████████| 36718/36718 [00:00<00:00, 518746.35 examples/s]\n",
      "Generating validation split: 100%|██████████| 3760/3760 [00:00<00:00, 251396.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b20595c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'train', 'validation'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596376e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets[\"validation\"] = load_dataset(\n",
    "    \"wikitext\", \n",
    "    \"wikitext-2-raw-v1\",\n",
    "    split=f\"train[:{5}%]\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "raw_datasets[\"train\"] = load_dataset(\n",
    "    \"wikitext\", \n",
    "    \"wikitext-2-raw-v1\",\n",
    "    split=f\"train[{5}%:]\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "babe027a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'train', 'validation'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70c985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"FacebookAI/roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc23812",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"FacebookAI/roberta-base\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "050fe98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"FacebookAI/roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.47.0\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "635dddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f80b8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizerFast(name_or_path='FacebookAI/roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8492d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(model_name, config=config, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f21f092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1bc97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_half(x):\n",
    "    x1, x2 = x.chunk(2, dim=-1)\n",
    "    return torch.cat((-x2, x1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae454d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff4169cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0350,  1.3051,  0.9520,  0.7832, -1.2975,  0.9312],\n",
       "         [-0.7057, -0.3037,  1.2212, -0.2418, -0.4070,  0.9999],\n",
       "         [-1.0507, -0.5150, -0.7030,  0.7170,  0.1704, -0.0524]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a06e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7832,  1.2975, -0.9312, -1.0350,  1.3051,  0.9520],\n",
       "         [ 0.2418,  0.4070, -0.9999, -0.7057, -0.3037,  1.2212],\n",
       "         [-0.7170, -0.1704,  0.0524, -1.0507, -0.5150, -0.7030]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotate_half(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e0179b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def apply_rotary_pos_emb(q, k, cos, sin):\n",
    "    return (q * cos) + (rotate_half(q) * sin), (k * cos) + (rotate_half(k) * sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5f528b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 10000\n",
    "dim = 256\n",
    "inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7a89b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2410df48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(10).type_as(inv_freq)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbce3304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(10, dtype=inv_freq.dtype)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09bd5c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6627c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = torch.einsum(\"i,j -> ij\", t, inv_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5d4d231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c1d99",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c441b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.0000e+00, 9.3057e-01, 8.6596e-01,  ..., 1.2409e-04, 1.1548e-04,\n",
       "         1.0746e-04],\n",
       "        [2.0000e+00, 1.8611e+00, 1.7319e+00,  ..., 2.4819e-04, 2.3096e-04,\n",
       "         2.1492e-04],\n",
       "        ...,\n",
       "        [7.0000e+00, 6.5140e+00, 6.0618e+00,  ..., 8.6866e-04, 8.0835e-04,\n",
       "         7.5223e-04],\n",
       "        [8.0000e+00, 7.4446e+00, 6.9277e+00,  ..., 9.9275e-04, 9.2383e-04,\n",
       "         8.5969e-04],\n",
       "        [9.0000e+00, 8.3751e+00, 7.7937e+00,  ..., 1.1168e-03, 1.0393e-03,\n",
       "         9.6715e-04]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0251f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1351e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        base = 10000\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "        self.seq_len_cached = None\n",
    "        self.cos_cached = None\n",
    "        self.sin_cached = None\n",
    "\n",
    "    def _update_cached(self, x, seq_dim):\n",
    "        seq_len = x.shape[seq_dim]\n",
    "\n",
    "        if seq_len != self.seq_len_cached:\n",
    "            self.seq_len_cached = seq_len\n",
    "            t = torch.arange(x.shape[seq_dim], device=x.device)\n",
    "            freqs = torch.einsum(\"i,j -> ij\", t, self.inv_freq)\n",
    "            emb = torch.cat((freqs, freqs), dim=-1).to(x.device)\n",
    "\n",
    "            self.cos_cached = emb.cos()[None, None, :, :]\n",
    "            self.sin_cached = emb.sin()[None, None, :, :]\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
