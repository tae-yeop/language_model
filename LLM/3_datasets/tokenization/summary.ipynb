{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45863ff5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 사전에 학습된 토크나이저는 설정, 어휘, 병합표(merges) 파일을 그대로 읽어옴    \n",
    "\n",
    "# Hub에서 파일을 받아옴\n",
    "# config.json, tokenizer.json, vocab.txt, merges.txt, special_tokens_map.json\n",
    "AutoTokenizer.from_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4a8c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 새로운 토큰 추가 : 기존의 임베딩 테이블을 그대로 쓰기 위해서\n",
    "tokenizer.add_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c31eddb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# simple tokenizer\n",
    "def simple_tokenizer(text):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', ,text)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "sentence = \"자연어 처리는 재미있습니다.\"\n",
    "print(simple_tokenizer(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37273f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# BPE Tokenizer 테스트\n",
    "import tiktoken\n",
    "\n",
    "tik_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"Hello, world. Is this-- a test?\"\n",
    "\n",
    "integers = tik_tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(\"Encoded integers:\", integers)\n",
    "\n",
    "\n",
    "strings = tik_tokenizer.decode(integers)\n",
    "\n",
    "print(\"Decoded strings:\", strings)\n",
    "\n",
    "print(tik_tokenizer.n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b79e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# BPE via Hugging Face transformers\n",
    "from transformers import GPT2Tokenizer\n",
    "hf_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "print(hf_tokenizer(strings)[\"input_ids\"])\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "hf_tokenizer_fast = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "print(hf_tokenizer_fast(strings)[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b746ca7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b90aa2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 학습\n",
    "\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")\n",
    "\n",
    "naver_df = pd.read_table('ratings.txt')\n",
    "naver_df = naver_df.dropna(how='any')\n",
    "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(naver_df['document']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002bf5d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(\n",
    "    lowercase=False, # 대소문자 구분여부\n",
    "    strip_accents=False # 악센트 제거 é → e, ô → o\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ac843",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_file = 'naver_review.txt'\n",
    "vocab_size = 30000\n",
    "limit_alphabet = 6000\n",
    "min_frequency = 5\n",
    "\n",
    "tokenizer.train(files=data_file,\n",
    "                vocab_size=vocab_size,\n",
    "                limit_alphabet=limit_alphabet, # 병합 전의 초기 토큰의 허용 개수\n",
    "                min_frequency=min_frequency) # 최소 해당 횟수만큼 등장한 쌍(pair)의 경우에만 병합 대상이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181e18d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 학습 완료 후 vocab 저장\n",
    "tokenizer.save_model('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f891e4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# vocab 로드\n",
    "df = pd.read_fwf('vocab.txt', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245a488",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode('아 배고픈데 짜장면먹고싶다')\n",
    "print('토큰화 결과 :',encoded.tokens)\n",
    "print('정수 인코딩 :',encoded.ids)\n",
    "print('디코딩 :',tokenizer.decode(encoded.ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6211ad0a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode('커피 한잔의 여유를 즐기다')\n",
    "print('토큰화 결과 :',encoded.tokens)\n",
    "print('정수 인코딩 :',encoded.ids)\n",
    "print('디코딩 :',tokenizer.decode(encoded.ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2edb6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57831799",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 새로운 도메인에 이용시\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046963b",
   "metadata": {},
   "source": [
    "자연어용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e289eea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
